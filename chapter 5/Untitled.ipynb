{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b93cd8-38b2-4b52-9333-c34da1110921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779fc8e-ef34-49b8-92e2-a552eb3e41ab",
   "metadata": {},
   "source": [
    "\n",
    "## Query Instances\n",
    "\n",
    "We are given three query instances and are tasked with predicting whether it will be a good day to surf for each instance.\n",
    "\n",
    "| ID  | Wave Size (ft) | Wave Period (secs) | Wind Speed (MPH/hr) | Good to Surf |\n",
    "|-----|----------------|--------------------|---------------------|--------------|\n",
    "| q1  | 8              | 15                 | 2                   | ?            |\n",
    "| q2  | 8              | 2                  | 18                  | ?            |\n",
    "| q3  | 6              | 11                 | 4                   | ?            |\n",
    "\n",
    "## Euclidean Distance Calculation\n",
    "\n",
    "### Query q1: (8, 15, 2)\n",
    "- Calculated distances to dataset points:\n",
    "  - ID 1: \\( \\approx 3.61 \\)\n",
    "  - ID 2: \\( \\approx 13.38 \\)\n",
    "  - ID 3: \\( \\approx 5.48 \\)\n",
    "  - ID 4: \\( \\approx 3.32 \\)\n",
    "  - ID 5: \\( \\approx 16.40 \\)\n",
    "  - ID 6: \\( \\approx 22.29 \\)\n",
    "- **Nearest neighbor**: ID 4 (distance \\( \\approx 3.32 \\))\n",
    "- **Prediction**: **\"yes\"**\n",
    "\n",
    "### Query q2: (8, 2, 18)\n",
    "- Calculated distances to dataset points:\n",
    "  - ID 1: \\( \\approx 18.49 \\)\n",
    "  - ID 2: \\( \\approx 12.08 \\)\n",
    "  - ID 3: \\( \\approx 16.15 \\)\n",
    "  - ID 4: \\( \\approx 18.06 \\)\n",
    "  - ID 5: \\( 10 \\)\n",
    "  - ID 6: \\( \\approx 2.83 \\)\n",
    "- **Nearest neighbor**: ID 6 (distance \\( \\approx 2.83 \\))\n",
    "- **Prediction**: **\"no\"**\n",
    "\n",
    "### Query q3: (6, 11, 4)\n",
    "- Calculated distances to dataset points:\n",
    "  - ID 1: \\( \\approx 4.12 \\)\n",
    "  - ID 2: \\( \\approx 8.66 \\)\n",
    "  - ID 3: \\( \\approx 1.41 \\)\n",
    "  - ID 4: \\( \\approx 1.73 \\)\n",
    "  - ID 5: \\( \\approx 11.54 \\)\n",
    "  - ID 6: \\( \\approx 18.79 \\)\n",
    "- **Nearest neighbor**: ID 3 (distance \\( \\approx 1.41 \\))\n",
    "- **Prediction**: **\"yes\"**\n",
    "\n",
    "## Final Predictions:\n",
    "- **q1**: **\"yes\"**\n",
    "- **q2**: **\"no\"**\n",
    "- **q3**: **\"yes\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4528cc-6ceb-4c80-b4cd-827ea8599fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c84856b0-bc0e-4ca9-b0fa-cd43d52f1601",
   "metadata": {},
   "source": [
    "# Q 2 Email span Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fde9f7-e798-4c8f-831c-861464b7dca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1a4ef23-4743-4411-82c1-abe5fcb9f5a2",
   "metadata": {},
   "source": [
    "# Email Spam Filtering Using Nearest Neighbor\n",
    "\n",
    "This document outlines the solution to an Email Spam Filtering problem using a Nearest Neighbor algorithm with different distance metrics and methods.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset contains 5 emails represented as a bag-of-words feature set with the target feature indicating whether each email is spam.\n",
    "\n",
    "| ID  | money | free | of  | gambling | fun | machine | learning | spam  |\n",
    "| --- | ----- | ---- | --- | -------- | --- | ------- | -------- | ----- |\n",
    "| 1   | 3     | 0    | 0   | 0        | 0   | 0       | 0        | true  |\n",
    "| 2   | 1     | 2    | 1   | 1        | 1   | 0       | 0        | true  |\n",
    "| 3   | 0     | 0    | 1   | 1        | 1   | 0       | 0        | true  |\n",
    "| 4   | 0     | 1    | 0   | 1        | 3   | 1       | 1        | false |\n",
    "| 5   | 0     | 1    | 0   | 0        | 0   | 1       | 1        | false |\n",
    "\n",
    "## Query Email\n",
    "The query email is: **\"machine learning of free\"**\n",
    "\n",
    "The corresponding feature vector is: `[0, 1, 1, 0, 0, 1, 1]`.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Nearest Neighbor Model using Euclidean Distance\n",
    "\n",
    "### Solution:\n",
    "The Euclidean distances between the query email and each of the dataset points are calculated using the formula:\n",
    "\n",
    "\\[\n",
    "d(p, q) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}\n",
    "\\]\n",
    "\n",
    "- **Distance to ID 1**:  \n",
    "  \\[\n",
    "  d = \\sqrt{(0 - 3)^2 + (1 - 0)^2 + (1 - 0)^2 + (0 - 0)^2 + (0 - 0)^2 + (1 - 0)^2 + (1 - 0)^2} = \\sqrt{9 + 1 + 1 + 0 + 0 + 1 + 1} = \\sqrt{13} \\approx 3.61\n",
    "  \\]\n",
    "  \n",
    "- **Distance to ID 2**:  \n",
    "  \\[\n",
    "  d = \\sqrt{(0 - 1)^2 + (1 - 2)^2 + (1 - 1)^2 + (0 - 1)^2 + (0 - 1)^2 + (1 - 0)^2 + (1 - 0)^2} = \\sqrt{1 + 1 + 0 + 1 + 1 + 1 + 1} = \\sqrt{6} \\approx 2.45\n",
    "  \\]\n",
    "\n",
    "- **Distance to ID 3**:  \n",
    "  \\[\n",
    "  d = \\sqrt{(0 - 0)^2 + (1 - 0)^2 + (1 - 1)^2 + (0 - 1)^2 + (0 - 1)^2 + (1 - 0)^2 + (1 - 0)^2} = \\sqrt{0 + 1 + 0 + 1 + 1 + 1 + 1} = \\sqrt{5} \\approx 2.24\n",
    "  \\]\n",
    "\n",
    "- **Distance to ID 4**:  \n",
    "  \\[\n",
    "  d = \\sqrt{(0 - 0)^2 + (1 - 1)^2 + (1 - 0)^2 + (0 - 1)^2 + (0 - 3)^2 + (1 - 1)^2 + (1 - 1)^2} = \\sqrt{0 + 0 + 1 + 1 + 9 + 0 + 0} = \\sqrt{11} \\approx 3.32\n",
    "  \\]\n",
    "\n",
    "- **Distance to ID 5**:  \n",
    "  \\[\n",
    "  d = \\sqrt{(0 - 0)^2 + (1 - 1)^2 + (1 - 0)^2 + (0 - 0)^2 + (0 - 0)^2 + (1 - 1)^2 + (1 - 1)^2} = \\sqrt{0 + 0 + 1 + 0 + 0 + 0 + 0} = \\sqrt{1} = 1\n",
    "  \\]\n",
    "\n",
    "**Nearest neighbor**: ID 5 (distance = 1)\n",
    "\n",
    "**Prediction**: **false**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. k-NN Model with k = 3 using Euclidean Distance\n",
    "\n",
    "### Solution:\n",
    "The three nearest neighbors are:\n",
    "\n",
    "1. **ID 5** (distance = 1.00, class = false)\n",
    "2. **ID 3** (distance = 2.24, class = true)\n",
    "3. **ID 2** (distance = 2.45, class = true)\n",
    "\n",
    "Using majority voting, 2 out of 3 neighbors have the class **true**.\n",
    "\n",
    "**Prediction**: **true**\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Weighted k-NN Model with k = 5 using Reciprocal of Squared Euclidean Distance\n",
    "\n",
    "### Solution:\n",
    "For weighted \\( k \\)-NN, the weight is the reciprocal of the squared Euclidean distance:\n",
    "\n",
    "\\[\n",
    "\\text{Weight} = \\frac{1}{d^2}\n",
    "\\]\n",
    "\n",
    "The 5 nearest neighbors and their weights are:\n",
    "\n",
    "1. **ID 5** (distance = 1.00, weight = \\( \\frac{1}{1^2} = 1 \\), class = false)\n",
    "2. **ID 3** (distance = 2.24, weight = \\( \\frac{1}{2.24^2} \\approx 0.199 \\), class = true)\n",
    "3. **ID 2** (distance = 2.45, weight = \\( \\frac{1}{2.45^2} \\approx 0.167 \\), class = true)\n",
    "4. **ID 4** (distance = 3.32, weight = \\( \\frac{1}{3.32^2} \\approx 0.091 \\), class = false)\n",
    "5. **ID 1** (distance = 3.61, weight = \\( \\frac{1}{3.61^2} \\approx 0.077 \\), class = true)\n",
    "\n",
    "- Total weight for **true**: \\( 0.199 + 0.167 + 0.077 = 0.443 \\)\n",
    "- Total weight for **false**: \\( 1 + 0.091 = 1.091 \\)\n",
    "\n",
    "Since the total weight for **false** is greater, the prediction is **false**.\n",
    "\n",
    "**Prediction**: **false**\n",
    "\n",
    "---\n",
    "\n",
    "## 4. k-NN Model with k = 3 using Manhattan Distance\n",
    "\n",
    "### Solution:\n",
    "The Manhattan distance between two points \\( p \\) and \\( q \\) is:\n",
    "\n",
    "\\[\n",
    "d(p, q) = \\sum_{i=1}^{n} |p_i - q_i|\n",
    "\\]\n",
    "\n",
    "The Manhattan distances between the query email and each of the dataset points are:\n",
    "\n",
    "- **Distance to ID 1**:  \n",
    "  \\[\n",
    "  d = |0 - 3| + |1 - 0| + |1 - 0| + |0 - 0| + |0 - 0| + |1 - 0| + |1 - 0| = 7\n",
    "  \\]\n",
    "\n",
    "- **Distance to ID 2**:  \n",
    "  \\[\n",
    "  d = |0 - 1| + |1 - 2| + |1 - 1| + |0 - 1| + |0 - 1| + |1 - 0| + |1 - 0| = 6\n",
    "  \\]\n",
    "\n",
    "- **Distance to ID 3**:  \n",
    "  \\[\n",
    "  d = |0 - 0| + |1 - 0| + |1 - 1| + |0 - 1| + |0 - 1| + |1 - 0| + |1 - 0| = 5\n",
    "  \\]\n",
    "\n",
    "- **Distance to ID 4**:  \n",
    "  \\[\n",
    "  d = |0 - 0| + |1 - 1| + |1 - 0| + |0 - 1| + |0 - 3| + |1 - 1| + |1 - 1| = 5\n",
    "  \\]\n",
    "\n",
    "- **Distance to ID 5**:  \n",
    "  \\[\n",
    "  d = |0 - 0| + |1 - 1| + |1 - 0| + |0 - 0| + |0 - 0| + |1 - 1| + |1 - 1| = 1\n",
    "  \\]\n",
    "\n",
    "The three nearest neighbors are:\n",
    "\n",
    "1. **ID 5** (distance = 1, class = false)\n",
    "2. **ID 3** (distance = 5, class = true)\n",
    "3. **ID 4** (distance = 5, class = false)\n",
    "\n",
    "Using majority voting, 2 out of 3 neighbors have the class **false**.\n",
    "\n",
    "**Prediction**: **false**\n",
    "\n",
    "---\n",
    "\n",
    "## 5. k-NN Model with k = 3 using Cosine Similarity\n",
    "\n",
    "### Solution:\n",
    "Cosine similarity measures the cosine of the angle between two vectors. The formula for cosine similarity is:\n",
    "\n",
    "\\[\n",
    "\\text{Cosine Similarity} = \\frac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3992b3a6-b407-48b6-93e0-9c291011d1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50d8e9e7-665e-4d8d-b965-d4e0ae06adfb",
   "metadata": {},
   "source": [
    "# 3 Curruption Predition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c2344-480b-40ce-96a0-f66ef86643c5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The dataset includes the following descriptive features:\n",
    "1. **Life Exp** – Mean life expectancy at birth.\n",
    "2. **Top-10 Income** – Percentage of annual income going to the top 10% of earners.\n",
    "3. **Infant Mortality** – Number of infant deaths per 1,000 births.\n",
    "4. **Mil Spend** – Percentage of GDP spent on the military.\n",
    "5. **School Years** – Mean number of years spent in school by adult females.\n",
    "\n",
    "We are tasked with predicting the CPI for Russia using the following values:\n",
    "\n",
    "- **Life Expectancy**: 67.62\n",
    "- **Top-10 Income**: 31.68\n",
    "- **Infant Mortality**: 10.0\n",
    "- **Military Spending**: 3.87\n",
    "- **School Years**: 12.9\n",
    "\n",
    "---\n",
    "\n",
    "### a. 3-Nearest Neighbor Prediction using Euclidean Distance\n",
    "\n",
    "#### Work:\n",
    "1. Calculate the Euclidean distance between Russia’s data and the other countries in the dataset:\n",
    "\\[\n",
    "d(p, q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + (p_3 - q_3)^2 + (p_4 - q_4)^2 + (p_5 - q_5)^2}\n",
    "\\]\n",
    "Where \\(p\\) represents Russia's values and \\(q\\) represents each country's values.\n",
    "\n",
    "2. Identify the three closest neighbors based on the smallest Euclidean distances.\n",
    "\n",
    "#### Solution:\n",
    "The predicted CPI is the average of the CPIs of the three nearest neighbors.\n",
    "\n",
    "---\n",
    "\n",
    "### b. Weighted \\(k\\)-NN Prediction using \\(k = 16\\) with Reciprocal of Squared Euclidean Distance\n",
    "\n",
    "#### Work:\n",
    "1. Calculate the Euclidean distances for all 16 countries.\n",
    "2. Apply the weighting scheme:\n",
    "\\[\n",
    "\\text{Weight} = \\frac{1}{d^2}\n",
    "\\]\n",
    "3. Compute the weighted average CPI for all countries in the dataset, where each country's contribution is weighted by the reciprocal of the squared distance.\n",
    "\n",
    "#### Solution:\n",
    "The predicted CPI is the weighted average of the CPIs for all 16 countries.\n",
    "\n",
    "---\n",
    "\n",
    "### c. 3-Nearest Neighbor Prediction using Normalized Data and Euclidean Distance\n",
    "\n",
    "#### Work:\n",
    "1. Normalize each feature using range normalization:\n",
    "\\[\n",
    "x_{\\text{normalized}} = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n",
    "\\]\n",
    "2. Recompute the Euclidean distances between Russia and the other countries using the normalized feature values.\n",
    "3. Identify the three closest neighbors based on the smallest normalized Euclidean distances.\n",
    "\n",
    "#### Solution:\n",
    "The predicted CPI is the average of the CPIs of the three nearest neighbors from the normalized dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### d. Weighted \\(k\\)-NN Prediction using Normalized Data and Reciprocal of Squared Euclidean Distance\n",
    "\n",
    "#### Work:\n",
    "1. Normalize the dataset using the same range normalization as in part **c**.\n",
    "2. Recompute the Euclidean distances in the normalized feature space.\n",
    "3. Apply the same weighting scheme:\n",
    "\\[\n",
    "\\text{Weight} = \\frac{1}{d^2}\n",
    "\\]\n",
    "4. Compute the weighted average CPI using the normalized distances.\n",
    "\n",
    "#### Solution:\n",
    "The predicted CPI is the weighted average of the CPIs from the normalized dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### e. Comparison with Actual CPI\n",
    "\n",
    "#### Work:\n",
    "The actual CPI for Russia in 2011 was 2.4488. Compare the predictions from parts **a**, **b**, **c**, and **d** to the actual value and determine which method was the most accurate.\n",
    "\n",
    "#### Solution:\n",
    "The method with the closest predicted CPI to 2.4488 is the most accurate.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c0dee-fab7-456e-9dfb-a17201284554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac072166-519e-4af6-917c-39da13d69958",
   "metadata": {},
   "source": [
    "# 4 Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08512684-8fe1-4825-bb71-b89cd7ed6137",
   "metadata": {},
   "source": [
    "# Recommender Systems\n",
    "\n",
    "This document provides the solution to the problem of building a recommender system for an online shop based on customer item purchase behavior. The system is trained on a dataset that captures whether items have been bought or not by customers. The goal is to implement a similarity-based model to recommend items to customers based on the behavior of other similar customers.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset includes the purchase behavior of two customers, where the items have either been bought (`true`) or not bought (`false`).\n",
    "\n",
    "| ID  | Item 107 | Item 498 | Item 7256 | Item 28063 | Item 75328 |\n",
    "| --- | -------- | -------- | --------- | ---------- | ---------- |\n",
    "| 1   | true     | true     | true      | false      | false      |\n",
    "| 2   | true     | false    | false     | true       | true       |\n",
    "\n",
    "## Task\n",
    "\n",
    "### 1. Which of the following three similarity indexes do you think the system should be based on?\n",
    "\n",
    "- **Russell-Rao** similarity index:\n",
    "\\[\n",
    "\\text{Russell-Rao}(X, Y) = \\frac{CP(X, Y)}{P}\n",
    "\\]\n",
    "  \n",
    "- **Sokal-Michener** similarity index:\n",
    "\\[\n",
    "\\text{Sokal-Michener}(X, Y) = \\frac{CP(X, Y) + CA(X, Y)}{P}\n",
    "\\]\n",
    "  \n",
    "- **Jaccard** similarity index:\n",
    "\\[\n",
    "\\text{Jaccard}(X, Y) = \\frac{CP(X, Y)}{CP(X, Y) + PA(X, Y) + AP(X, Y)}\n",
    "\\]\n",
    "\n",
    "### Solution:\n",
    "For a recommender system where we want to find the most similar customer based on the items they have bought, the **Jaccard similarity index** is a suitable choice. This is because the Jaccard index focuses on the intersection of purchases (common items bought) relative to the total number of distinct items considered. It effectively captures the similarity based on the items that both customers have bought, ignoring cases where both have not bought certain items, which is ideal for recommendation scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What items will the system recommend to the following customer?\n",
    "\n",
    "| ID    | Item 107 | Item 498 | Item 7256 | Item 28063 | Item 75328 |\n",
    "| ----- | -------- | -------- | --------- | ---------- | ---------- |\n",
    "| Query | true     | false    | true      | false      | false      |\n",
    "\n",
    "### Work:\n",
    "\n",
    "1. Using the **Jaccard similarity index**, compare the \"Query\" customer with Customer 1 and Customer 2 to find the most similar customer.\n",
    "2. Once the most similar customer is identified, recommend the items that this similar customer has bought but that the \"Query\" customer has not bought.\n",
    "\n",
    "**Step 1: Calculate Jaccard similarity:**\n",
    "\n",
    "- **Between Query and Customer 1:**\n",
    "\n",
    "\\[\n",
    "\\text{Jaccard}(X_{\\text{Query}}, X_1) = \\frac{\\text{Items Both Bought}}{\\text{Items Query or Customer 1 Bought}} = \\frac{2}{4} = 0.5\n",
    "\\]\n",
    "\n",
    "- **Between Query and Customer 2:**\n",
    "\n",
    "\\[\n",
    "\\text{Jaccard}(X_{\\text{Query}}, X_2) = \\frac{1}{5} = 0.2\n",
    "\\]\n",
    "\n",
    "**Step 2: Identify most similar customer:**\n",
    "- Customer 1 is the most similar to the query customer with a Jaccard similarity of 0.5.\n",
    "\n",
    "**Step 3: Recommend items:**\n",
    "- Customer 1 has bought Item 498, which the query customer has not bought.\n",
    "\n",
    "### Solution:\n",
    "The system will recommend **Item 498** to the query customer based on the similarity with Customer 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cab20-89ca-4641-ad70-7886bd873e40",
   "metadata": {},
   "source": [
    "\n",
    "# Rent Prerdition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2d569-d052-457a-a43f-1b7d35b1be15",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. Create a k-d tree for this dataset\n",
    "\n",
    "#### Work:\n",
    "The k-d tree is a binary tree used for organizing points in a k-dimensional space. In this case, we are using 2-dimensional data with features **Rent** and **Size**. The tree will be constructed as follows:\n",
    "\n",
    "1. The first split is based on **Rent** (since Rent is the first feature in the order).\n",
    "2. The second split is based on **Size** (the second feature in the order).\n",
    "3. Subsequent splits alternate between **Rent** and **Size**.\n",
    "\n",
    "#### Solution:\n",
    "The k-d tree will be built by recursively splitting the dataset based on the median value of the current feature at each node. Here's the resulting k-d tree structure:\n",
    "\n",
    "- Root node: Split on **Rent** at the median value of Rent.\n",
    "- Left subtree: Split on **Size** at the median value of Size.\n",
    "- Right subtree: Continue alternating between **Rent** and **Size**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Nearest Neighbor Search Using the k-d Tree\n",
    "\n",
    "#### Query:\n",
    "The query point is a property with:\n",
    "- **Size**: 1,000 square feet\n",
    "- **Rent**: 2,200 dollars\n",
    "\n",
    "#### Work:\n",
    "1. Starting from the root of the k-d tree, compare the query point with each node's splitting feature to traverse the tree.\n",
    "2. After reaching a leaf node, backtrack and check other nodes to ensure the closest neighbor is found.\n",
    "\n",
    "#### Solution:\n",
    "Using the k-d tree constructed in part 1, the nearest neighbor to the query point (**Size** = 1,000, **Rent** = 2,200) is found by traversing the tree and comparing the distances between the query point and the nodes.\n",
    "\n",
    "**Nearest Neighbor**: Property ID 2 (Size = 1,315, Rent = 1,800, Price = 820,000)\n",
    "\n",
    "The nearest neighbor is the property with ID 2, which has a similar size and rent to the query property.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b6c4d-b386-4258-9a1a-345e83a12df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
